# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_secure_password

# Embedding Model Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking Configuration
# Use contextualized text (with hierarchical headings) for embeddings (recommended: true)
# Improves RAG retrieval by adding document structure context to each chunk
CHUNK_USE_CONTEXTUALIZED=true


# PDF Parsing Configuration (Docling Advanced Options)
# Image resolution scale factor (higher = better quality, slower processing)
PDF_IMAGES_SCALE=3.0
# Generate full page images (set to true for comprehensive analysis)
PDF_GENERATE_PAGE_IMAGES=false
# Extract and save picture/figure images
PDF_GENERATE_PICTURE_IMAGES=true
# Enable OCR for scanned documents (recommended: true)
PDF_DO_OCR=true
# Enable advanced table structure extraction with cell matching
PDF_DO_TABLE_STRUCTURE=true
# Enable AI-powered image descriptions (requires additional setup)
PDF_DO_PICTURE_DESCRIPTION=true

# VLM (Vision Language Model) Configuration - Built-in GraniteDocling
# Enable VLM parsing mode (uses built-in Granite model, no external server needed)
PDF_USE_VLM=false
# VLM model type: 'transformers' (CPU/CUDA) or 'mlx' (macOS Apple Silicon GPU with MPS)
# Use 'mlx' for ~10x faster processing on M1/M2/M3/M4 Macs
PDF_VLM_MODEL_TYPE=mlx

# Accelerator Configuration (CPU/GPU acceleration)
# Device: 'auto' (default), 'cpu', 'mps' (macOS), 'cuda' (NVIDIA GPU)
PDF_ACCELERATOR_DEVICE=auto
# Number of CPU threads for processing
PDF_ACCELERATOR_THREADS=8

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
